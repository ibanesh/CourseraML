{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401)\n",
      "(10, 26)\n",
      "(10285,)\n"
     ]
    }
   ],
   "source": [
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "\n",
    "mat_content = sio.loadmat('ex4data1.mat')\n",
    "X = mat_content['X']\n",
    "y = mat_content['y']\n",
    "\n",
    "mat_content = sio.loadmat('ex4weights.mat')\n",
    "Theta1 = mat_content['Theta1']\n",
    "Theta2 = mat_content['Theta2']\n",
    "\n",
    "nn_params = np.concatenate((np.ravel(Theta1),np.ravel(Theta2)),0)\n",
    "print Theta1.shape\n",
    "print Theta2.shape\n",
    "print nn_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size,\n",
    "                   num_labels, X, y, lam):\n",
    "    Theta1 = np.reshape(nn_params[0:hidden_layer_size*(input_layer_size+1)],[hidden_layer_size,input_layer_size+1])\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size*(input_layer_size+1):],[num_labels,hidden_layer_size+1])\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "    X = np.concatenate((np.ones([m,1]),X),1)\n",
    "    \n",
    "    #Feed Forward\n",
    "    z2 = Theta1.dot(X.T)  # 25x5000\n",
    "    a2 = np.concatenate((np.ones([1,m]),sigmoid(z2)),0) # 26x5000\n",
    "    z3 = Theta2.dot(a2)\n",
    "    h = sigmoid(z3.T)\n",
    "    \n",
    "    temp = np.zeros([m,num_labels])\n",
    "    for i in xrange(m):\n",
    "        temp[i][y[i]-1] = 1\n",
    "    y = temp\n",
    "    \n",
    "    h_flat = h.ravel()\n",
    "    y_flat = y.ravel()\n",
    "    J = (1.0/m)*(-y_flat.T.dot(np.log(h_flat)) - (1-y_flat).dot(np.log(1-h_flat)) )\n",
    "    \n",
    "    # Regularization of Cost\n",
    "    reg = (lam/(2.0*m))*(np.sum(Theta1[:,1:]**2)+np.sum(Theta2[:,1:]**2))\n",
    "    J += reg\n",
    "    \n",
    "    #Back propagation\n",
    "    del3 = h-y #5000x10\n",
    "    del2 = (del3.dot(Theta2))*((a2*(1-a2)).T) #5000x26\n",
    "    del2 = del2[:,1:]\n",
    "    \n",
    "    Theta2_grad = (1.0/m)*(a2.dot(del3)).T\n",
    "    Theta1_grad = (1.0/m)*(del2.T.dot(X))\n",
    "    \n",
    "    #adding regularization\n",
    "    Theta1_grad[:,1:] += (1.0/m)*(lam*Theta1[:,1:])\n",
    "    Theta2_grad[:,1:] += (1.0/m)*(lam*Theta2[:,1:])\n",
    "    \n",
    "    grad = np.concatenate([Theta1_grad.ravel(),Theta2_grad.ravel()])\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnGradient(nn_params, input_layer_size, hidden_layer_size,\n",
    "               num_labels, X, y, lam):\n",
    "    Theta1 = np.reshape(nn_params[0:hidden_layer_size*(input_layer_size+1)],[hidden_layer_size,input_layer_size+1])\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size*(input_layer_size+1):],[num_labels,hidden_layer_size+1])\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "    X = np.concatenate((np.ones([m,1]),X),1)\n",
    "    \n",
    "    #Feed Forward\n",
    "    z2 = Theta1.dot(X.T)  # 25x5000\n",
    "    a2 = np.concatenate((np.ones([1,m]),sigmoid(z2)),0) # 26x5000\n",
    "    z3 = Theta2.dot(a2)\n",
    "    h = sigmoid(z3.T)\n",
    "    \n",
    "    #Back propagation\n",
    "    del3 = h-y #5000x10\n",
    "    del2 = (del3.dot(Theta2))*((a2*(1-a2)).T) #5000x26\n",
    "    del2 = del2[:,1:]\n",
    "    \n",
    "    Theta2_grad = (1.0/m)*(a2.dot(del3)).T\n",
    "    Theta1_grad = (1.0/m)*(del2.T.dot(X))\n",
    "    \n",
    "    #adding regularization\n",
    "    Theta1_grad[:,1:] += (1.0/m)*(lam*Theta1[:,1:])\n",
    "    Theta2_grad[:,1:] += (1.0/m)*(lam*Theta2[:,1:])\n",
    "    \n",
    "    grad = np.concatenate([Theta1_grad.ravel(),Theta2_grad.ravel()])\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randInitWeights(L_in, L_out):\n",
    "    epsilonInit = 0.12\n",
    "    return np.random.rand(L_out, 1 + L_in) *((2 * epsilonInit) - epsilonInit)\n",
    "\n",
    "initial_Theta1 = randInitWeights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = randInitWeights(hidden_layer_size, num_labels)\n",
    "initial_nn_params = np.concatenate([Theta1.ravel(),Theta2.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam =1\n",
    "\n",
    "nn_params_opt = opt.minimize(fun=nnCostFunction,x0=initial_nn_params,\n",
    "              args=(input_layer_size, hidden_layer_size,num_labels,X,y,lam),\n",
    "                             method='TNC', jac=True, options={'maxiter': 50})\n",
    "    \n",
    "Theta1 = np.reshape(nn_params_opt.x[0:hidden_layer_size*(input_layer_size+1)],[hidden_layer_size,input_layer_size+1])\n",
    "Theta2 = np.reshape(nn_params_opt.x[hidden_layer_size*(input_layer_size+1):],[num_labels,hidden_layer_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "99.2\n"
     ]
    }
   ],
   "source": [
    "def predict(Theta1,Theta2,X):\n",
    "    m = X.shape[0]\n",
    "    num_labels = Theta2.shape[0]\n",
    "    \n",
    "    p = np.zeros([m,1])\n",
    "    \n",
    "    h1 = sigmoid(Theta1.dot(np.concatenate((np.ones([m,1]),X),1).T))\n",
    "    h2 = sigmoid(Theta2.dot(np.concatenate((np.ones([1,m]),h1),0)))\n",
    "    \n",
    "    return np.squeeze(h2.argmax(0)+1)\n",
    "\n",
    "pred = predict(Theta1,Theta2,X)\n",
    "print \"Accuracy: \"\n",
    "print np.mean(pred == y.squeeze())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CourseraML",
   "language": "python",
   "name": "courseraml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
